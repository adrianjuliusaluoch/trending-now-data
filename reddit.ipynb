{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-25T06:35:35.606258Z",
          "iopub.status.busy": "2025-10-25T06:35:35.605965Z",
          "iopub.status.idle": "2025-10-25T06:35:53.220800Z",
          "shell.execute_reply": "2025-10-25T06:35:53.220038Z",
          "shell.execute_reply.started": "2025-10-25T06:35:35.606233Z"
        },
        "id": "XLl5X_4td5S7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Google Cloud BigQuery\n",
        "from google.cloud import bigquery\n",
        "from google.api_core.exceptions import NotFound\n",
        "\n",
        "# Reddit API\n",
        "import praw\n",
        "import requests\n",
        "\n",
        "# Data Manipulation & Exploration\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "\n",
        "# Access Credentials\n",
        "import json\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "now = datetime.now()\n",
        "year = now.year\n",
        "month = now.strftime(\"%b\").lower()  # jan, feb, mar\n",
        "table_suffix = f\"{year}_{month}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-25T06:37:16.669855Z",
          "iopub.status.busy": "2025-10-25T06:37:16.668951Z",
          "iopub.status.idle": "2025-10-25T06:37:16.674206Z",
          "shell.execute_reply": "2025-10-25T06:37:16.673349Z",
          "shell.execute_reply.started": "2025-10-25T06:37:16.669812Z"
        },
        "id": "aK4y-0xzd5S9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Initialize Client Object\n",
        "client = bigquery.Client()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-25T06:37:20.079183Z",
          "iopub.status.busy": "2025-10-25T06:37:20.078530Z",
          "iopub.status.idle": "2025-10-25T06:37:20.082791Z",
          "shell.execute_reply": "2025-10-25T06:37:20.082068Z",
          "shell.execute_reply.started": "2025-10-25T06:37:20.079157Z"
        },
        "id": "P2DyQJ0Vd5S-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Path to Reddit API Credentials\n",
        "credentials = 'client_secrets.json'\n",
        "\n",
        "# Read Credentials from JSON file\n",
        "with open(credentials) as f:\n",
        "    creds = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-25T06:37:21.865049Z",
          "iopub.status.busy": "2025-10-25T06:37:21.864656Z",
          "iopub.status.idle": "2025-10-25T06:37:21.999181Z",
          "shell.execute_reply": "2025-10-25T06:37:21.998397Z",
          "shell.execute_reply.started": "2025-10-25T06:37:21.865003Z"
        },
        "id": "porZQD0Hd5TA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Python Reddit API Wrapper\n",
        "reddit = praw.Reddit(client_id=creds['client_id'],\n",
        "                     client_secret=creds['client_secret'],\n",
        "                     user_agent=creds['user_agent'],\n",
        "                     redirect_uri=creds['redirect_uri'],\n",
        "                     refresh_token=creds['refresh_token'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-25T06:37:23.959264Z",
          "iopub.status.busy": "2025-10-25T06:37:23.958874Z",
          "iopub.status.idle": "2025-10-25T06:38:48.552816Z",
          "shell.execute_reply": "2025-10-25T06:38:48.552070Z",
          "shell.execute_reply.started": "2025-10-25T06:37:23.959241Z"
        },
        "id": "oYFfdZpDd5TB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Create an Empty DataFrame for Result Storage\n",
        "bigdata = pd.DataFrame()\n",
        "\n",
        "# Provide List of Different Genres\n",
        "genres = ['rising']\n",
        "\n",
        "# Provide List of East African Subreddits\n",
        "subreddits = [\"Kenya\"]\n",
        "\n",
        "# Loop through Each Subreddit\n",
        "for sub in subreddits:\n",
        "    search = reddit.subreddit(sub)\n",
        "    print(f\"ðŸ“¥ Extracting posts from r/{sub}...\")\n",
        "\n",
        "    # Loop through Genres while Extracting Posts\n",
        "    for genre in genres:\n",
        "        posts = []\n",
        "\n",
        "        # Submit Requests\n",
        "        submissions = getattr(search, genre)(limit=1000)\n",
        "\n",
        "        for post in submissions:\n",
        "            created_at_datetime = datetime.fromtimestamp(post.created)\n",
        "            today_date = datetime.today()\n",
        "            genr = genre\n",
        "\n",
        "            # Compute derived metrics\n",
        "            engagement_rate = (post.score + post.num_comments) / (search.subscribers / 1000)\n",
        "            engagement_intensity = (post.score * getattr(post, 'upvote_ratio', 1)) + post.num_comments + getattr(post, 'total_awards_received', 0)\n",
        "\n",
        "            # Append to list\n",
        "            posts.append([\n",
        "                genr,\n",
        "                post.title,\n",
        "                getattr(post, 'link_flair_text', None),  # flair (topic/category)\n",
        "                post.score,\n",
        "                post.id,\n",
        "                str(post.subreddit),\n",
        "                post.url,\n",
        "                post.num_comments,\n",
        "                post.selftext,\n",
        "                getattr(post, 'upvote_ratio', None),\n",
        "                getattr(post, 'total_awards_received', 0),\n",
        "                str(post.author),\n",
        "                getattr(post, 'over_18', False),\n",
        "                getattr(post, 'spoiler', False),\n",
        "                getattr(post, 'is_self', None),\n",
        "                created_at_datetime,\n",
        "                today_date,\n",
        "                search.subscribers,\n",
        "                engagement_rate,\n",
        "                engagement_intensity\n",
        "            ])\n",
        "\n",
        "        # Convert to DataFrame\n",
        "        data = pd.DataFrame(\n",
        "            posts,\n",
        "            columns=[\n",
        "                'genre', 'title', 'flair', 'score', 'id', 'subreddit', 'url',\n",
        "                'num_comments', 'body', 'upvote_ratio', 'awards', 'author',\n",
        "                'over_18', 'spoiler', 'is_self', 'created', 'today_date',\n",
        "                'subscribers', 'engagement_rate', 'engagement_intensity'\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Concatenate\n",
        "        if not data.empty:\n",
        "            bigdata = pd.concat([bigdata, data], ignore_index=True)\n",
        "\n",
        "print(\"âœ… Reddit weekly data extraction complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-25T06:42:20.303210Z",
          "iopub.status.busy": "2025-10-25T06:42:20.302063Z",
          "iopub.status.idle": "2025-10-25T06:42:20.319673Z",
          "shell.execute_reply": "2025-10-25T06:42:20.318788Z",
          "shell.execute_reply.started": "2025-10-25T06:42:20.303176Z"
        },
        "id": "W0kr4ujPd5TF",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Drop Duplicates\n",
        "bigdata.drop_duplicates(subset='id', keep='first', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-25T06:45:27.703968Z",
          "iopub.status.busy": "2025-10-25T06:45:27.703197Z",
          "iopub.status.idle": "2025-10-25T06:45:32.969158Z",
          "shell.execute_reply": "2025-10-25T06:45:32.968120Z",
          "shell.execute_reply.started": "2025-10-25T06:45:27.703939Z"
        },
        "id": "q63g6oqad5TH",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define Table ID\n",
        "table_id = f\"data-storage-485106.reddit.trending_now_{table_suffix}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if now.day == 1: \n",
        "\n",
        "    # Check if current month table already has current month data\n",
        "    try:\n",
        "        check_sql = f\"\"\"\n",
        "                    SELECT COUNT(*) AS cnt\n",
        "                    FROM `{table_id}`\n",
        "                    WHERE EXTRACT(MONTH FROM CAST(start_date AS DATETIME)) = {now.month}\n",
        "                      AND EXTRACT(YEAR FROM CAST(start_date AS DATETIME)) = {now.year}\n",
        "                    \"\"\"\n",
        "        check_df = client.query(check_sql).to_dataframe()\n",
        "        has_current_month_data = check_df.loc[0, \"cnt\"] > 0\n",
        "    except NotFound:\n",
        "        has_current_month_data = False  # Table doesn't exist yet\n",
        "  \n",
        "    if not has_current_month_data:\n",
        "      try:\n",
        "        prev_month_date = now.replace(day=1) - timedelta(days=1)\n",
        "        prev_table_suffix = f\"{prev_month_date.year}_{prev_month_date.strftime('%b').lower()}\"\n",
        "        prev_table_id = f\"data-storage-485106.reddit.trending_now_{prev_table_suffix}\"\n",
        "        \n",
        "        try:\n",
        "            prev_data = client.query(\n",
        "                f\"SELECT * FROM `{prev_table_id}` ORDER BY start_date DESC\"\n",
        "            ).to_dataframe()\n",
        "            bigdata = pd.concat([prev_data, bigdata], ignore_index=True)\n",
        "            print(f\"Appended {len(prev_data)} rows from previous month table.\")\n",
        "        except NotFound:\n",
        "            print(\"No previous month table found, skipping append.\")\n",
        "        \n",
        "        job = client.load_table_from_dataframe(\n",
        "            bigdata,\n",
        "            table_id,\n",
        "            job_config=bigquery.LoadJobConfig(write_disposition=\"WRITE_APPEND\")\n",
        "        )\n",
        "        job.result()\n",
        "        print(f\"All data loaded into {table_id}, total rows: {len(bigdata)}\")\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\"Error during 1st-of-month load: {e}\")\n",
        "\n",
        "else:\n",
        "    # ðŸ”¥ NORMAL WORKFLOW (this was missing)\n",
        "    job = client.load_table_from_dataframe(\n",
        "        bigdata,\n",
        "        table_id,\n",
        "        job_config=bigquery.LoadJobConfig(write_disposition=\"WRITE_APPEND\")\n",
        "    )\n",
        "    job.result()\n",
        "    print(f\"Normal load completed into {table_id}, rows: {len(bigdata)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-25T06:45:38.313526Z",
          "iopub.status.busy": "2025-10-25T06:45:38.313248Z",
          "iopub.status.idle": "2025-10-25T06:45:41.285881Z",
          "shell.execute_reply": "2025-10-25T06:45:41.285126Z",
          "shell.execute_reply.started": "2025-10-25T06:45:38.313507Z"
        },
        "id": "w3fLg0bvd5TI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define SQL Query to Retrieve All Records from BigQuery\n",
        "sql = (f\"\"\"\n",
        "        SELECT *\n",
        "        FROM `{table_id}`;\n",
        "       \"\"\")\n",
        "\n",
        "# Run SQL Query\n",
        "data = client.query(sql).to_dataframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-25T06:46:04.773617Z",
          "iopub.status.busy": "2025-10-25T06:46:04.773321Z",
          "iopub.status.idle": "2025-10-25T06:46:04.904165Z",
          "shell.execute_reply": "2025-10-25T06:46:04.903310Z",
          "shell.execute_reply.started": "2025-10-25T06:46:04.773593Z"
        },
        "id": "lJNOolLwd5TJ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Drop Duplicated Records\n",
        "data.drop_duplicates(subset='id', keep='first', inplace=True)\n",
        "\n",
        "# Replace Original BigQuery Table\n",
        "client.delete_table(table_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-25T06:46:11.436594Z",
          "iopub.status.busy": "2025-10-25T06:46:11.435888Z",
          "iopub.status.idle": "2025-10-25T06:46:14.994537Z",
          "shell.execute_reply": "2025-10-25T06:46:14.993868Z",
          "shell.execute_reply.started": "2025-10-25T06:46:11.436566Z"
        },
        "id": "16dKLz6Fd5TK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Upload New BigQuery Table\n",
        "job = client.load_table_from_dataframe(data,table_id)\n",
        "while job.state != 'DONE':\n",
        "    time.sleep(1)\n",
        "    job.reload()\n",
        "    print(job.state)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 31153,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
